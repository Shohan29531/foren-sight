# Where processed assets live
DATA_DIR=./data

# Frame sampling (frames per second)
FRAME_SAMPLE_FPS=1

# CLIP model (open_clip)
CLIP_MODEL=ViT-B-32
CLIP_PRETRAINED=openai

# Event proposal sensitivity (higher -> fewer events)
CHANGEPOINT_Z=2.5
CLIP_SECONDS_AROUND_EVENT=8

# Zone/ROI rule defaults
ZONE_MOTION_THRESH=0.02
ZONE_LOITER_SECONDS=20
ZONE_ENABLE_PERSON=1

# LLM provider for nicer labels + answers
# options: none | openai | ollama
LLM_PROVIDER=none

# OpenAI (optional)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Ollama (optional)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:14b
